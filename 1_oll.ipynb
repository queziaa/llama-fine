{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from tool import soft_match_score,output_tf,filter,merge,add_slang_prompt,OpenAi_api,assembly_prompt,load_train_byWORKTYPE\n",
    "import threading\n",
    "key=\"sk-ed3f695be16b4638bae6e1be62bf3ff3\"\n",
    "# proxy=\"socks5://username:password@proxy.example.com:1080\"\n",
    "WORKNAME = 'outputnew_5.json'\n",
    "WORKTYPY = 5\n",
    "if str(WORKTYPY) not in WORKNAME:\n",
    "    print('WORKNAME must contain WORKTYPY')\n",
    "    exit(0) \n",
    "# 创建线程锁，用于保护文件写入操作\n",
    "output_lock = threading.Lock()\n",
    "log_lock = threading.Lock()\n",
    "\n",
    "data = load_train_byWORKTYPE('./DATA/train.json',WORKTYPY)\n",
    "print('数据量', len(data))\n",
    "# 读取已处理的数据ID\n",
    "conduct = {} \n",
    "with open(WORKNAME, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        temp = json.loads(line)\n",
    "        # conduct.add(temp['id'])\n",
    "        if WORKTYPY == 3 or WORKTYPY == 5:\n",
    "            conduct[temp['id']] = True\n",
    "        elif WORKTYPY == 4:\n",
    "            # conduct[temp['id']] = temp['Target'] + temp['Argument']\n",
    "            conduct[str(temp['id']) + temp['Target'] + temp['Argument']] = True\n",
    "        else:\n",
    "            print('WORKTYPY must be 3 or 4')\n",
    "\n",
    "print('已经处理了', len(conduct), '条数据')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义处理单个数据的函数\n",
    "def process_item(item):\n",
    "    if WORKTYPY == 3 or WORKTYPY == 5:\n",
    "        if item['id'] in conduct:\n",
    "            return None\n",
    "    elif WORKTYPY == 4:\n",
    "        if str(item['id']) + item['Target'] + item['Argument'] in conduct:\n",
    "            return None\n",
    "    # print('正在处理', item['id'])\n",
    "\n",
    "    if WORKTYPY == 1:\n",
    "        response = OpenAi_api(key,content=item['content'],work=WORKTYPY,isSlang=True)\n",
    "    elif WORKTYPY == 2:\n",
    "        response = OpenAi_api(key,content=item,work=WORKTYPY,isSlang=True)\n",
    "    elif WORKTYPY == 3:\n",
    "        response = OpenAi_api(key,content=item['content'],work=WORKTYPY,isSlang=item['Target'])\n",
    "    elif WORKTYPY == 4:\n",
    "        response = OpenAi_api(key,content=item,work=WORKTYPY,isSlang=None)\n",
    "    elif WORKTYPY == 5:\n",
    "        response = OpenAi_api(key,content=item,work=WORKTYPY,isSlang=None)\n",
    "    else:\n",
    "        raise ValueError(\"WORKTYPY must be 1 or 2\")\n",
    "    results = response.choices[0].message.content\n",
    "    \n",
    "    if WORKTYPY == 5:\n",
    "        tempdict = {\n",
    "            'results': results,\n",
    "            'id': item['id'],\n",
    "        }\n",
    "    elif WORKTYPY != 3:\n",
    "        tempdict = {\n",
    "            'content': item['content'],\n",
    "            'Argument': item['Argument'],\n",
    "            'Target': item['Target'],\n",
    "            'id': item['id'],\n",
    "            'results': results\n",
    "        }\n",
    "    else:\n",
    "        tempdict = {\n",
    "            'content': item['content'],\n",
    "            'Target': item['Target'],\n",
    "            'id': item['id'],\n",
    "            'results': results\n",
    "        }    \n",
    "    # 使用锁保护文件写入\n",
    "    with output_lock:\n",
    "        with open(WORKNAME, 'a', encoding='utf-8') as file:\n",
    "            file.write(json.dumps(tempdict, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    templog = response.to_dict()\n",
    "    templog['train_id'] = item['id']\n",
    "    \n",
    "    with log_lock:\n",
    "        with open('log.json', 'a', encoding='utf-8') as file:\n",
    "            file.write(json.dumps(templog, ensure_ascii=False) + '\\n')\n",
    "            \n",
    "    return item['id']\n",
    "\n",
    "\n",
    "# # 使用线程池并发处理数据\n",
    "# with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:\n",
    "#     future_to_item = {executor.submit(process_item, item): item for item in to_process}\n",
    "#     with tqdm(total=len(future_to_item)) as pbar:\n",
    "#         for future in concurrent.futures.as_completed(future_to_item):\n",
    "#             result = future.result()\n",
    "#             pbar.update(1)\n",
    "# 单线程处理数据\n",
    "for item in tqdm(data):\n",
    "    process_item(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
