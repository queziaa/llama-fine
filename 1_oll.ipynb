{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from tool import load_train_byWORKTYPE,OpenAi_api\n",
    "import threading\n",
    "key=\"sk-afb5f670349645f18a0c4635c4bccb22\"\n",
    "# proxy=\"socks5://username:password@proxy.example.com:1080\"\n",
    "WORKNAME = 'outputnew_6.json'\n",
    "WORKTYPY = 6\n",
    "if str(WORKTYPY) not in WORKNAME:\n",
    "    print('WORKNAME must contain WORKTYPY')\n",
    "    exit(0) \n",
    "# 创建线程锁，用于保护文件写入操作\n",
    "output_lock = threading.Lock()\n",
    "log_lock = threading.Lock()\n",
    "\n",
    "data = load_train_byWORKTYPE('./DATA/train_hiv.json',WORKTYPY)\n",
    "print('数据量', len(data))\n",
    "# 读取已处理的数据ID\n",
    "conduct = {} \n",
    "# 去重函数\n",
    "def deduplicate(temp):\n",
    "    index = None\n",
    "    if WORKTYPY == 3 or WORKTYPY == 5:\n",
    "        index = temp['id']\n",
    "    elif WORKTYPY == 4:\n",
    "        index = str(temp['id']) + temp['Target'] + temp['Argument']\n",
    "    elif WORKTYPY == 6:\n",
    "        index = str(temp['id']) + temp['Target']\n",
    "    else:\n",
    "        print('WORKTYPY must be 3 or 4')\n",
    "\n",
    "    if index in conduct:\n",
    "        return True\n",
    "    else:\n",
    "        conduct[index] = True\n",
    "        return False\n",
    "    \n",
    "\n",
    "with open(WORKNAME, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        temp = json.loads(line)\n",
    "        deduplicate(temp)\n",
    "print('已经处理了', len(conduct), '条数据')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 206/2713 [45:24<10:36:56, 15.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这里提供了一个'歧视类型判断'任务介绍和示例，你不需要完成这个任务，已经给出了答案，根据示例去分析的提取过程，输出以下段落：俚语分析、语义分析、歧视类型判断、类型json输出。json List输出模板:\n",
      "[\n",
      "    '歧视类型 String',\n",
      "    ...\n",
      "]\n",
      "**任务介绍**\n",
      "给出的'社交媒体发言'中作者对'评论目标'发表了歧视言论，判断作者对该目标的'歧视类型'(种族歧视/同性恋歧视/艾滋病歧视/地域歧视/性别歧视)。\n",
      "**示例**\n",
      "社交媒体发言：和黑人生的黄黑混血，登登你的大眼睛看看有多丑，黄白混血还能大量平凡混血中还能出几个颜值巅峰，黄黑混血我没见过一个，一代比一代丑，除了基因顽强，能把黄种人白种人基因染黑，这不是基因退化是什么\n",
      "评论目标：黄黑混血\n",
      "歧视类型：['种族歧视']\n",
      " ChatCompletion(id='2c30b0bf-507e-408a-8a00-190366e07afd', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 俚语分析\\n- \"登登你的大眼睛看看有多丑\"：这里的\"登登\"可能是一种口语化的表达，带有贬义和嘲讽的语气。\\n- \"基因顽强\"：这里的\"顽强\"被用来讽刺性地描述基因的\"强势\"，带有负面含义。\\n- \"基因退化\"：这是一个贬义表达，暗示黄黑混血的基因是退化的、劣等的。\\n\\n### 语义分析\\n- 发言者通过对比黄黑混血和黄白混血，认为黄黑混血\"一代比一代丑\"，并声称黄黑混血的基因是\"退化\"的。\\n- 发言者将肤色（黄、黑、白）与外貌和基因优劣直接关联，暗示黑色基因是负面的、具有\"染色\"其他基因的能力。\\n- 发言者用\"我没见过一个\"来强化自己的偏见，暗示黄黑混血普遍外貌不佳。\\n\\n### 歧视类型判断\\n- 发言者基于肤色（黑、黄、白）对混血人群进行外貌和基因优劣的评价，并将黑色基因视为负面特征，这属于典型的**种族歧视**。\\n- 发言中没有涉及性别、性取向、地域或艾滋病的相关内容，因此其他歧视类型不适用。\\n\\n### 类型json输出\\n```json\\n[\\n    \"种族歧视\"\\n]\\n```', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1745147186, model='deepseek-chat', object='chat.completion', service_tier=None, system_fingerprint='fp_3d5141a69a_prod0225', usage=CompletionUsage(completion_tokens=273, prompt_tokens=197, total_tokens=470, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=64), prompt_cache_hit_tokens=64, prompt_cache_miss_tokens=133))\n"
     ]
    }
   ],
   "source": [
    "# 定义处理单个数据的函数\n",
    "def process_item(item):\n",
    "    if deduplicate(item):\n",
    "        return None\n",
    "    response = OpenAi_api(key,item,WORKTYPY,log=True)\n",
    "    results = response.choices[0].message.content\n",
    "    item['results'] = results\n",
    "\n",
    "    # 使用锁保护文件写入\n",
    "    with output_lock:\n",
    "        with open(WORKNAME, 'a', encoding='utf-8') as file:\n",
    "            file.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    templog = response.to_dict()\n",
    "    templog['train_id'] = item['id']\n",
    "    \n",
    "    with log_lock:\n",
    "        with open('log.json', 'a', encoding='utf-8') as file:\n",
    "            file.write(json.dumps(templog, ensure_ascii=False) + '\\n')\n",
    "            \n",
    "    return item['id']\n",
    "\n",
    "# # 使用线程池并发处理数据\n",
    "# with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:\n",
    "#     future_to_item = {executor.submit(process_item, item): item for item in to_process}\n",
    "#     with tqdm(total=len(future_to_item)) as pbar:\n",
    "#         for future in concurrent.futures.as_completed(future_to_item):\n",
    "#             result = future.result()\n",
    "#             pbar.update(1)\n",
    "# 单线程处理数据\n",
    "for item in tqdm(data):\n",
    "    process_item(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
